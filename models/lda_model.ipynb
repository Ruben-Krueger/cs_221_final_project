{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import corpora, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DATA_SET = []\n",
    "# DATA_FILE = \"../Data/data_full_simple_short_2.csv\"\n",
    "DATA_FILE = \"synthetic_data_mutated.csv\"\n",
    "SYNTHETIC_DATA_TEST_FILE = \"test_synthetic_data_mutated.csv\"\n",
    "PROTEIN_SEQUENCE_INDEX = 1\n",
    "TM_INDEX = 0\n",
    "INTERVAL = 15\n",
    "MAX_RANGE = 15\n",
    "MAX_RANGES = 1\n",
    "TOPICS_TO_GET = 10\n",
    "WORDS_PER_TOPIC = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_dictionary(interval, min_temp, max_temp):\n",
    "    \"\"\"\n",
    "    :param interval: \n",
    "    :param min_temp: \n",
    "    :param max_temp: \n",
    "    :return: an array of ranges [min, max, string representing the range]\n",
    "    :return: a dictionary mapping the range to a (min, max) tuple\n",
    "    \"\"\"\n",
    "    vals_and_strings = []\n",
    "    range_dict = {}\n",
    "    print(min_temp)\n",
    "    print(max_temp)\n",
    "    for i in [x for x in range(int(min_temp) - interval, int(max_temp) + interval) if x % interval == 0]:\n",
    "        vals_and_strings.append([int(i), int(i + interval - 1), str(i) + \"-\" + str(i + interval - 1)])\n",
    "        range_dict[str(i) + \"-\" + str(i + interval - 1)] = (int(i), int(i + interval - 1))\n",
    "    \n",
    "    return vals_and_strings, range_dict\n",
    "\n",
    "def separate_learn_and_test_data(data, using_synthetic_data):\n",
    "    \"\"\"\n",
    "    :param data: data to be randomized, in array structure\n",
    "    :param using_synthetic_data: a flag indicating if using synthetic data - thus, test data already prepared\n",
    "    :return: learning data, testing data\n",
    "    \"\"\"\n",
    "    if using_synthetic_data:\n",
    "        syn_data = get_data(SYNTHETIC_DATA_TEST_FILE)\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        new_data = []\n",
    "        for i in data:\n",
    "            if i not in syn_data:\n",
    "                new_data.append(i)\n",
    "        return new_data, get_data(SYNTHETIC_DATA_TEST_FILE)\n",
    "        \n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        return data, get_data(SYNTHETIC_DATA_TEST_FILE)\n",
    "    random.shuffle(data)\n",
    "    return(data[int(len(data) / 5):], data[:int(len(data) / 5)])\n",
    "    \n",
    "def set_data_based_on_dictionary(data, vals_and_strings):\n",
    "    \"\"\"\n",
    "    :param data: \n",
    "    :param vals_and_strings:\n",
    "    :return: \n",
    "    \"\"\"\n",
    "    topic_analysis_data = {}\n",
    "    for item in vals_and_strings:\n",
    "        for point in data:\n",
    "            if point[0] >= item[0] and point[0] <= item[1]:\n",
    "                if topic_analysis_data.get(item[2]) is not None:\n",
    "                    topic_analysis_data[item[2]].append(point[1])\n",
    "                else:\n",
    "                    topic_analysis_data[item[2]] = [point[1]]\n",
    "    return topic_analysis_data\n",
    "\n",
    "def compare_topic_arrs(topic1, topic2):\n",
    "#     print(topic1, topic2)\n",
    "    for i in topic1:\n",
    "        if i not in topic2:\n",
    "            return False\n",
    "    for i in topic2:\n",
    "        if i not in topic1:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def get_predicted_range(learned_topics, test_result_topics, range_dict):\n",
    "    \"\"\"\n",
    "    :param learned_topics: a dictionary matching each learned topic to the amino acids in that topic\n",
    "    :param test_result_topic: a 2d array of length TOPICS_TO_GET, returning topic from running the tests\n",
    "    :param range_dict: a dictionary mapping the range to a (min, max) tuple\n",
    "    :return: returns the range predicted, a (min, max) tuple\n",
    "    \"\"\"\n",
    "    d = {}\n",
    "    print(test_result_topics)\n",
    "    print(learned_topics)\n",
    "    matching_topics = []\n",
    "    for topic in learned_topics.keys():\n",
    "        for result in test_result_topics:\n",
    "            for t in learned_topics[topic]:\n",
    "                if compare_topic_arrs(result, t):\n",
    "                    if d.get(topic, None) is None:\n",
    "                        d[topic] = 1\n",
    "                    else:\n",
    "                        d[topic] += 1\n",
    "                    if len(matching_topics) == 0:\n",
    "                        print(t)\n",
    "                    matching_topics.append(topic)\n",
    "                    \n",
    "#     print(d)\n",
    "    # Convert matching topics array of strings (e.g. [\"320-329\", \"330-339\",...]) to integer form\n",
    "    \n",
    "    # Prediction Method 0\n",
    "#     print(d.items)\n",
    "#     list_of_tuples_sorted = sorted((value, key) for (key,value) in d.items())\n",
    "#     counted_ranges = 0\n",
    "#     min_val = None\n",
    "#     max_val = None\n",
    "#     if list_of_tuples_sorted is not None:\n",
    "#         for i in range(0, len(list_of_tuples_sorted)):\n",
    "#             print(list_of_tuples_sorted)\n",
    "#             new_index = len(list_of_tuples_sorted) - 1 - i\n",
    "#             if min_val is None or range_dict[list_of_tuples_sorted[new_index][1]][0] < min_val:\n",
    "#                 min_val = range_dict[list_of_tuples_sorted[new_index][1]][0]\n",
    "#             if max_val is None or range_dict[list_of_tuples_sorted[new_index][1]][1]  > max_val:\n",
    "#                 print(list_of_tuples_sorted[new_index][0])\n",
    "#                 max_val = range_dict[list_of_tuples_sorted[new_index][1]][1] \n",
    "#             counted_ranges += 1\n",
    "#             if counted_ranges >= MAX_RANGES:\n",
    "#                 break\n",
    "        \n",
    "#     return min_val, max_val\n",
    "\n",
    "    # Prediction Method 1\n",
    "    \n",
    "    min_val = None\n",
    "    max_val = None\n",
    "    print(matching_topics)\n",
    "    for t in matching_topics:\n",
    "        print(t)\n",
    "        return range_dict[t][0], range_dict[t][1]\n",
    "        if min_val is None or range_dict[t][0] < min_val:\n",
    "            min_val = range_dict[t][0]\n",
    "        if max_val is None or range_dict[t][1]  > max_val:\n",
    "            max_val = range_dict[t][1] \n",
    "        if max_val - min_val > MAX_RANGE - INTERVAL:\n",
    "            break\n",
    "    return min_val, max_val\n",
    "\n",
    "    # Prediction Method 2\n",
    "#     min_vals = []\n",
    "#     max_vals = []\n",
    "#     for t in matching_topics:\n",
    "#         min_vals.append(range_dict[t][0])\n",
    "#         max_vals.append(range_dict[t][1])\n",
    "#     min_avg = 0\n",
    "#     max_avg = 0\n",
    "#     for i in range(len(min_vals)):\n",
    "#         min_avg += min_vals[i] * (1 / len(min_vals))\n",
    "#         max_avg += max_vals[i] * (1 / len(max_vals))\n",
    "    return min_avg, max_avg\n",
    "    # Get entire range and return\n",
    "    \n",
    "def get_topic_data(data_array):\n",
    "    \"\"\"\n",
    "    :param data_array: an array of strings, representing the a range of data\n",
    "    :return: a 2D array of topics, where each topic is a few amino acids, of the form [['A', 'G', 'L'], ['G', 'F', 'L']...]\n",
    "    \"\"\"\n",
    "    texts = []\n",
    "    for item in data_array:\n",
    "        amino_acid = item.upper()\n",
    "        new_str = \"\"\n",
    "        for ch in amino_acid:\n",
    "            new_str += ch + \" \"\n",
    "        new_str.strip()\n",
    "        if new_str != \"\":\n",
    "            to_append = new_str.split(\" \")\n",
    "            to_append.pop(len(to_append) - 1)\n",
    "            texts.append(to_append)\n",
    "    dictionary = corpora.Dictionary(texts)\n",
    "    corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "    # LDA - Latent Dirichlet Allocation\n",
    "    ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics=TOPICS_TO_GET, id2word=dictionary, passes=10) #alpha='auto', eval_every=5)  #\n",
    "    # print(ldamodel.print_topics(num_topics=1, num_words=3))\n",
    "    topics = []\n",
    "    for i in range(TOPICS_TO_GET):\n",
    "        topic_filetered = []\n",
    "        topic = ldamodel.show_topic(i)\n",
    "        for j in range(WORDS_PER_TOPIC):\n",
    "            topic_filetered.append(topic[j][0])\n",
    "        topics.append(topic_filetered)\n",
    "    return topics\n",
    "\n",
    "def get_range_from_val(true_val, ranges):\n",
    "    for arr in ranges:\n",
    "#         print(here)\n",
    "        if int(true_val) >= arr[0] and int(true_val) <= arr[1]:\n",
    "            print((arr[0], arr[1]))\n",
    "            return (arr[0], arr[1])\n",
    "\n",
    "def get_data(file_name):\n",
    "    \"\"\"\n",
    "    :param file_name: the file name to be read\n",
    "    :return: the data, where the TM_INDEX gives the index of the TM and PROTEIN_SEQUENCE_INDEX gives the index of the protein\n",
    "    \"\"\"\n",
    "    with open(file_name, encoding='utf-8-sig') as f:\n",
    "        csv_reader = csv.reader(f)\n",
    "        two_d_arr = []\n",
    "        for row in csv_reader:\n",
    "            row_in_row = []\n",
    "            for v in row:\n",
    "                v = v.strip()\n",
    "                if len(row_in_row) == PROTEIN_SEQUENCE_INDEX:\n",
    "                    row_in_row.append(str(v))\n",
    "                elif len(row_in_row) == TM_INDEX:\n",
    "                    row_in_row.append(float(v))\n",
    "            two_d_arr.append(row_in_row)\n",
    "        return two_d_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting...\n",
      "34633\n",
      "315.25\n",
      "368.05\n",
      "[[300, 314, '300-314'], [315, 329, '315-329'], [330, 344, '330-344'], [345, 359, '345-359'], [360, 374, '360-374'], [375, 389, '375-389']]\n",
      "34633\n",
      "57\n",
      "1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-6cd4dce4ddfa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mlearned_topics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_topic_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdictionary_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;31m#Test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-2c2d5b82e2c9>\u001b[0m in \u001b[0;36mget_topic_data\u001b[0;34m(data_array)\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0mcorpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc2bow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;31m# LDA - Latent Dirichlet Allocation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m     \u001b[0mldamodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mldamodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLdaModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_topics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTOPICS_TO_GET\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid2word\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#alpha='auto', eval_every=5)  #\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m     \u001b[0;31m# print(ldamodel.print_topics(num_topics=1, num_words=3))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0mtopics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, corpus, num_topics, id2word, distributed, chunksize, passes, update_every, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, minimum_probability, random_state, ns_conf, minimum_phi_value, per_word_topics, callbacks, dtype)\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0muse_numpy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatcher\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunks_as_numpy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_numpy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minit_dir_prior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, corpus, chunksize, decay, offset, passes, update_every, eval_every, iterations, gamma_threshold, chunks_as_numpy)\u001b[0m\n\u001b[1;32m    978\u001b[0m                         \u001b[0mpass_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_no\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlencorpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m                     )\n\u001b[0;32m--> 980\u001b[0;31m                     \u001b[0mgammat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_estep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    981\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize_alpha\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36mdo_estep\u001b[0;34m(self, chunk, state)\u001b[0m\n\u001b[1;32m    740\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 742\u001b[0;31m         \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollect_sstats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    743\u001b[0m         \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msstats\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msstats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m         \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumdocs\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# avoids calling len(chunk) on a generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36minference\u001b[0;34m(self, chunk, collect_sstats)\u001b[0m\n\u001b[1;32m    692\u001b[0m                 \u001b[0;31m# the update for gamma gives this update. Cf. Lee&Seung 2001.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m                 \u001b[0mgammad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mexpElogthetad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcts\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mphinorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpElogbetad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m                 \u001b[0mElogthetad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdirichlet_expectation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgammad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    695\u001b[0m                 \u001b[0mexpElogthetad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mElogthetad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m                 \u001b[0mphinorm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpElogthetad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpElogbetad\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Get data\n",
    "summation = 0\n",
    "times = 1\n",
    "MAX_NAME = \"MAX\"\n",
    "MIN_NAME = \"MIN\"\n",
    "DEVIATION = \"SIGMA\"\n",
    "MEAN = \"MEAN\"\n",
    "statistics = {MAX_NAME: 0, MIN_NAME: 1, DEVIATION: 0, MEAN: 0}\n",
    "c_matrix = {}\n",
    "points = []\n",
    "for elbow in range(times):\n",
    "    print(\"Starting...\")\n",
    "    data = get_data(DATA_FILE)\n",
    "    print(len(data))\n",
    "    min_val = None\n",
    "    max_val = None\n",
    "    for i in data:\n",
    "        if min_val is None or i[TM_INDEX] < min_val:\n",
    "            min_val = i[TM_INDEX]\n",
    "        if max_val is None or i[TM_INDEX] > max_val:\n",
    "            max_val = i[TM_INDEX]\n",
    "    ranges, range_dict = set_dictionary(INTERVAL, min_val, max_val)\n",
    "    print(ranges)\n",
    "    # learning_data, test_data = train_test_split(data)\n",
    "    learning_data, test_data = separate_learn_and_test_data(data, True)\n",
    "    print(len(learning_data))\n",
    "    print(len(test_data))\n",
    "    # Add to topics in dictionary\n",
    "    # Learn\n",
    "    dictionary_data = set_data_based_on_dictionary(learning_data, ranges)\n",
    "    learned_topics = {}\n",
    "    count = 0\n",
    "    for key in dictionary_data.keys():\n",
    "        count += 1\n",
    "        print(count)\n",
    "        learned_topics[key] = get_topic_data(dictionary_data[key])\n",
    "\n",
    "    #Test\n",
    "    dictionary_data = set_data_based_on_dictionary(test_data, ranges)\n",
    "    test_results = {}\n",
    "    for item in test_data:\n",
    "        data = get_topic_data(item[PROTEIN_SEQUENCE_INDEX])\n",
    "    #     print(data)\n",
    "        if data is not None:\n",
    "            test_results[item[PROTEIN_SEQUENCE_INDEX]] = data, item[TM_INDEX]\n",
    "\n",
    "    # Get 3 ranges\n",
    "    win = 0\n",
    "    loss = 0\n",
    "    none_loss = 0\n",
    "    # print(test_results)\n",
    "    for result in test_results.keys():\n",
    "        true_val = test_results[result][1]\n",
    "        range_result = get_predicted_range(learned_topics, test_results[result][0], range_dict)\n",
    "        true_range = get_range_from_val(true_val, ranges)\n",
    "        if range_result[0] is not None and range_result[0] != 0 and range_result[1] is not None:\n",
    "            if int(true_val) >= range_result[0] and int(true_val) <= range_result[1]:\n",
    "                print(\"win: \" + str(range_result))\n",
    "                print(\"actual = \" + str(true_val))\n",
    "                win += 1\n",
    "                if true_range not in c_matrix:\n",
    "                    c_matrix[true_range] = {}\n",
    "                    c_matrix[true_range][range_result] = 1\n",
    "                else:\n",
    "                    if range_result not in c_matrix[true_range]:\n",
    "                        c_matrix[true_range][range_result] = 1\n",
    "                    else:\n",
    "                        c_matrix[true_range][range_result] += 1\n",
    "            else:\n",
    "                print(\"loss:\" + str(range_result))\n",
    "                print(\"actual = \" + str(true_val))\n",
    "                if true_range not in c_matrix:\n",
    "                    c_matrix[true_range] = {}\n",
    "                    c_matrix[true_range][range_result] = 1\n",
    "                else:\n",
    "                    if range_result not in c_matrix[true_range]:\n",
    "                        c_matrix[true_range][range_result] = 1\n",
    "                    else:\n",
    "                        c_matrix[true_range][range_result] += 1\n",
    "                loss += 1\n",
    "            print(\"\")\n",
    "        else:\n",
    "            if true_range not in c_matrix:\n",
    "                    c_matrix[true_range] = {}\n",
    "                    c_matrix[true_range][\"NONE\"] = 1\n",
    "            else:\n",
    "                if \"NONE\" not in c_matrix[true_range]:\n",
    "                    c_matrix[true_range][\"NONE\"] = 1\n",
    "                else:\n",
    "                    c_matrix[true_range][\"NONE\"] += 1\n",
    "            print(\"None: \" + str(true_val))\n",
    "            print(\"\")\n",
    "            none_loss += 1\n",
    "    summation += win/(loss + win)\n",
    "    print(win)\n",
    "    print(loss)\n",
    "    print(none_loss)\n",
    "    print(\"Final Results\")\n",
    "    print(\"Total Loss: \" + str(win/(loss + win + none_loss)))\n",
    "    print(\"Predicted Loss: \" + str(win/(loss + win)))\n",
    "    \n",
    "    pred_loss = win/(loss + win)\n",
    "    points.append(pred_loss)\n",
    "    if pred_loss < statistics[MIN_NAME]:\n",
    "        statistics[MIN_NAME] = pred_loss\n",
    "    if pred_loss > statistics[MAX_NAME]:\n",
    "        statistics[MAX_NAME] = pred_loss\n",
    "    statistics[MEAN] += 1/float(times) * float(pred_loss)\n",
    "print(points)\n",
    "for pt in points:\n",
    "    statistics[DEVIATION] += (pt - statistics[MEAN])**2\n",
    "statistics[DEVIATION] *= float(1)/(times - 1)\n",
    "dev = statistics[DEVIATION]\n",
    "statistics[DEVIATION] = math.sqrt(dev)\n",
    "print(summation/float(times))\n",
    "print(statistics)\n",
    "print(c_matrix)\n",
    "    # Then get topics for test\n",
    "    # If you get similar topics for test set, choose that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
