{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import corpora, models\n",
    "import math\n",
    "import csv\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(' ')\n",
    "TEST_DATA_SET = []\n",
    "DATA_FILE = \"../Data/data_full_simple.csv\"\n",
    "PROTEIN_SEQUENCE_INDEX = 1\n",
    "TM_INDEX = 0\n",
    "INTERVAL = 10\n",
    "TOPICS_TO_GET = 20\n",
    "WORDS_PER_TOPIC = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_dictionary(interval, min_temp, max_temp):\n",
    "    \"\"\"\n",
    "    :param interval: \n",
    "    :param min_temp: \n",
    "    :param max_temp: \n",
    "    :return: an array of ranges [min, max, string representing the range]\n",
    "    :return: a dictionary mapping the range to a (min, max) tuple\n",
    "    \"\"\"\n",
    "    vals_and_strings = []\n",
    "    range_dict = {}\n",
    "    for i in [x for x in range(int(min_temp) - interval, int(max_temp) + interval) if x % interval == 0]:\n",
    "        vals_and_strings.append([int(i), int(i + interval - 1), str(i) + \"-\" + str(i + interval - 1)])\n",
    "        range_dict[str(i) + \"-\" + str(i + interval - 1)] = (int(i), int(i + interval - 1))\n",
    "    return vals_and_strings, range_dict\n",
    "\n",
    "def separate_learn_and_test_data(data):\n",
    "    \"\"\"\n",
    "    :param data: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    random.shuffle(data)\n",
    "    return(data[int(len(data) / 5):], data[:int(len(data) / 5)])\n",
    "    \n",
    "def set_data_based_on_dictionary(data, vals_and_strings):\n",
    "    \"\"\"\n",
    "    :param data: \n",
    "    :param vals_and_strings:\n",
    "    :return: \n",
    "    \"\"\"\n",
    "    topic_analysis_data = {}\n",
    "    for item in vals_and_strings:\n",
    "        for point in data:\n",
    "            if point[0] >= item[0] and point[0] <= item[1]:\n",
    "                if topic_analysis_data.get(item[2]) is not None:\n",
    "                    topic_analysis_data[item[2]].append(point[1])\n",
    "                else:\n",
    "                    topic_analysis_data[item[2]] = [point[1]]\n",
    "    return topic_analysis_data\n",
    "\n",
    "def get_predicted_range(learned_topics, test_result_topics, range_dict):\n",
    "    \"\"\"\n",
    "    :param learned_topics: a dictionary matching each learned topic to the amino acids in that topic\n",
    "    :param test_result_topic: a 2d array of length TOPICS_TO_GET, returning topic from running the tests\n",
    "    :param range_dict: a dictionary mapping the range to a (min, max) tuple\n",
    "    :return: returns the range predicted, a (min, max) tuple\n",
    "    \"\"\"\n",
    "    matching_topics = []\n",
    "    for topic in learned_topics.keys():\n",
    "        for result in test_result_topics:\n",
    "            if result in learned_topics[topic]:\n",
    "                matching_topics.append(topic)\n",
    "    # Convert matching topics array of strings (e.g. [\"320-329\", \"330-339\",...]) to integer form\n",
    "    min_val = None\n",
    "    max_val = None\n",
    "    for t in matching_topics:\n",
    "        if min_val is None or range_dict[t][0] < min_val:\n",
    "            min_val = range_dict[t][0]\n",
    "        if max_val is None or range_dict[t][1]  > max_val:\n",
    "            max_val = range_dict[t][0] \n",
    "    return min_val, max_val\n",
    "    # Get entire range and return\n",
    "    \n",
    "def get_topic_data(data_array):\n",
    "    \"\"\"\n",
    "    :param data_array: an array of strings, representing the a range of data\n",
    "    :return: a 2D array of topics, where each topic is a few amino acids, of the form [['A', 'G', 'L'], ['G', 'F', 'L']...]\n",
    "    \"\"\"\n",
    "    texts = []\n",
    "    for item in data_array:\n",
    "        amino_acid = item.upper()\n",
    "        new_str = \"\"\n",
    "        for ch in amino_acid:\n",
    "            new_str += ch + \" \"\n",
    "        new_str.strip()\n",
    "        if new_str != \"\":\n",
    "            to_append = new_str.split(\" \")\n",
    "            to_append.pop(len(to_append) - 1)\n",
    "            texts.append(to_append)\n",
    "    dictionary = corpora.Dictionary(texts)\n",
    "    corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "    # LDA - Latent Dirichlet Allocation\n",
    "    ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics=TOPICS_TO_GET, id2word=dictionary, passes=10) #alpha='auto', eval_every=5)  #\n",
    "    # print(ldamodel.print_topics(num_topics=1, num_words=3))\n",
    "    topics = []\n",
    "    for i in range(TOPICS_TO_GET):\n",
    "        topic_filetered = []\n",
    "        topic = ldamodel.show_topic(i)\n",
    "        for j in range(WORDS_PER_TOPIC):\n",
    "            topic_filetered.append(topic[j][0])\n",
    "        topics.append(topic_filetered)\n",
    "#     print(topics)\n",
    "    return topics\n",
    "\n",
    "\n",
    "def get_data(file_name):\n",
    "    \"\"\"\n",
    "    :param file_name: the file name to be read\n",
    "    :return: the data, where the TM_INDEX gives the index of the TM and PROTEIN_SEQUENCE_INDEX gives the index of the protein\n",
    "    \"\"\"\n",
    "    with open(file_name, encoding='utf-8-sig') as f:\n",
    "        csv_reader = csv.reader(f)\n",
    "        two_d_arr = []\n",
    "        for row in csv_reader:\n",
    "            row_in_row = []\n",
    "            for v in row:\n",
    "                v = v.strip()\n",
    "                if len(row_in_row) == PROTEIN_SEQUENCE_INDEX:\n",
    "                    row_in_row.append(str(v))\n",
    "                elif len(row_in_row) == TM_INDEX:\n",
    "                    row_in_row.append(float(v))\n",
    "            two_d_arr.append(row_in_row)\n",
    "        return two_d_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting...\n",
      "win: (310, 360)\n",
      "win: (330, 380)\n",
      "loss:(310, 360)\n",
      "loss:(340, 340)\n",
      "win: (310, 360)\n",
      "win: (310, 380)\n",
      "loss:(330, 330)\n",
      "win: (310, 340)\n",
      "win: (320, 380)\n",
      "win: (320, 380)\n",
      "loss:(310, 340)\n",
      "loss:(330, 360)\n",
      "win: (330, 360)\n",
      "win: (320, 380)\n",
      "win: (310, 380)\n",
      "win: (320, 380)\n",
      "loss:(320, 320)\n",
      "win: (320, 360)\n",
      "loss:(320, 380)\n",
      "loss:(330, 340)\n",
      "loss:(320, 360)\n",
      "win: (310, 360)\n",
      "win: (310, 360)\n",
      "loss:(310, 360)\n",
      "loss:(320, 380)\n",
      "win: (310, 360)\n",
      "loss:(310, 340)\n",
      "win: (310, 360)\n",
      "win: (310, 380)\n",
      "win: (320, 340)\n",
      "win: (330, 380)\n",
      "win: (310, 380)\n",
      "loss:(310, 360)\n",
      "win: (320, 360)\n",
      "win: (320, 380)\n",
      "win: (320, 360)\n",
      "win: (310, 360)\n",
      "win: (330, 360)\n",
      "win: (310, 360)\n",
      "win: (310, 360)\n",
      "win: (320, 360)\n",
      "loss:(320, 340)\n",
      "win: (320, 360)\n",
      "loss:(320, 360)\n",
      "loss:(320, 320)\n",
      "win: (320, 360)\n",
      "win: (320, 340)\n",
      "win: (310, 340)\n",
      "win: (310, 360)\n",
      "win: (320, 360)\n",
      "win: (310, 380)\n",
      "win: (310, 360)\n",
      "win: (310, 360)\n",
      "win: (310, 360)\n",
      "loss:(310, 330)\n",
      "loss:(340, 340)\n",
      "win: (310, 340)\n",
      "win: (310, 380)\n",
      "loss:(310, 340)\n",
      "win: (310, 340)\n",
      "win: (330, 340)\n",
      "win: (310, 340)\n",
      "loss:(330, 330)\n",
      "win: (320, 380)\n",
      "win: (310, 360)\n",
      "loss:(320, 360)\n",
      "loss:(310, 360)\n",
      "loss:(310, 330)\n",
      "win: (310, 340)\n",
      "loss:(320, 340)\n",
      "win: (320, 360)\n",
      "loss:(310, 340)\n",
      "win: (310, 380)\n",
      "win: (310, 340)\n",
      "loss:(340, 340)\n",
      "win: (310, 360)\n",
      "win: (320, 360)\n",
      "win: (310, 360)\n",
      "win: (310, 360)\n",
      "win: (320, 360)\n",
      "loss:(310, 360)\n",
      "win: (310, 360)\n",
      "win: (310, 360)\n",
      "loss:(320, 340)\n",
      "win: (310, 360)\n",
      "loss:(310, 330)\n",
      "win: (320, 360)\n",
      "win: (320, 380)\n",
      "win: (320, 380)\n",
      "win: (310, 360)\n",
      "win: (310, 380)\n",
      "win: (310, 360)\n",
      "win: (310, 360)\n",
      "win: (310, 360)\n",
      "win: (310, 360)\n",
      "win: (320, 360)\n",
      "loss:(310, 340)\n",
      "loss:(330, 360)\n",
      "win: (310, 380)\n",
      "win: (310, 360)\n",
      "loss:(310, 360)\n",
      "win: (310, 380)\n",
      "loss:(330, 330)\n",
      "win: (310, 360)\n",
      "loss:(310, 340)\n",
      "loss:(330, 360)\n",
      "win: (310, 380)\n",
      "win: (310, 380)\n",
      "win: (310, 360)\n",
      "win: (330, 380)\n",
      "loss:(310, 360)\n",
      "win: (310, 380)\n",
      "win: (320, 360)\n",
      "loss:(310, 340)\n",
      "loss:(360, 360)\n",
      "win: (310, 360)\n",
      "win: (310, 360)\n",
      "loss:(320, 360)\n",
      "win: (320, 360)\n",
      "win: (310, 360)\n",
      "loss:(320, 340)\n",
      "win: (310, 360)\n",
      "win: (320, 360)\n",
      "win: (330, 340)\n",
      "win: (310, 360)\n",
      "loss:(320, 360)\n",
      "win: (320, 360)\n",
      "loss:(310, 330)\n",
      "win: (310, 340)\n",
      "loss:(320, 330)\n",
      "loss:(340, 360)\n",
      "win: (320, 340)\n",
      "win: (310, 360)\n",
      "win: (320, 340)\n",
      "win: (310, 340)\n",
      "loss:(330, 360)\n",
      "win: (310, 330)\n",
      "win: (310, 380)\n",
      "win: (310, 320)\n",
      "win: (320, 380)\n",
      "loss:(320, 380)\n",
      "loss:(310, 360)\n",
      "win: (320, 360)\n",
      "win: (330, 380)\n",
      "win: (310, 360)\n",
      "win: (310, 360)\n",
      "win: (310, 360)\n",
      "win: (310, 360)\n",
      "loss:(330, 340)\n",
      "win: (310, 360)\n",
      "win: (320, 360)\n",
      "win: (330, 340)\n",
      "win: (310, 340)\n",
      "win: (310, 380)\n",
      "loss:(310, 320)\n",
      "win: (310, 340)\n",
      "win: (310, 360)\n",
      "loss:(320, 320)\n",
      "loss:(320, 320)\n",
      "loss:(310, 360)\n",
      "win: (320, 340)\n",
      "win: (310, 380)\n",
      "loss:(330, 360)\n",
      "win: (310, 330)\n",
      "win: (310, 330)\n",
      "win: (320, 380)\n",
      "loss:(320, 330)\n",
      "win: (310, 360)\n",
      "win: (310, 360)\n",
      "loss:(320, 320)\n",
      "win: (320, 360)\n",
      "win: (310, 360)\n",
      "loss:(310, 330)\n",
      "win: (320, 360)\n",
      "loss:(360, 360)\n",
      "win: (320, 360)\n",
      "win: (320, 360)\n",
      "loss:(310, 340)\n",
      "loss:(320, 360)\n",
      "win: (310, 380)\n",
      "win: (320, 360)\n",
      "win: (320, 380)\n",
      "loss:(320, 380)\n",
      "loss:(330, 330)\n",
      "123\n",
      "61\n",
      "4\n",
      "Final results = 0.6542553191489362\n"
     ]
    }
   ],
   "source": [
    "# Get data\n",
    "print(\"Starting...\")\n",
    "data = get_data(DATA_FILE)\n",
    "min_val = None\n",
    "max_val = None\n",
    "for i in data:\n",
    "    if min_val is None or i[TM_INDEX] < min_val:\n",
    "        min_val = i[TM_INDEX]\n",
    "    if max_val is None or i[TM_INDEX] > max_val:\n",
    "        max_val = i[TM_INDEX]\n",
    "ranges, range_dict = set_dictionary(INTERVAL, min_val, max_val)\n",
    "test_data, learning_data = separate_learn_and_test_data(data)\n",
    "\n",
    "# Add to topics in dictionary\n",
    "# Learn\n",
    "dictionary_data = set_data_based_on_dictionary(learning_data, ranges)\n",
    "learned_topics = {}\n",
    "for key in dictionary_data.keys():\n",
    "    learned_topics[key] = get_topic_data(dictionary_data[key])\n",
    "    \n",
    "# Test\n",
    "dictionary_data = set_data_based_on_dictionary(test_data, ranges)\n",
    "test_results = {}\n",
    "for item in test_data:\n",
    "    data = get_topic_data(item[PROTEIN_SEQUENCE_INDEX])\n",
    "#     print(data)\n",
    "    if data is not None:\n",
    "        test_results[item[PROTEIN_SEQUENCE_INDEX]] = data, item[TM_INDEX]\n",
    "\n",
    "# Get 3 ranges\n",
    "win = 0\n",
    "loss = 0\n",
    "none_loss = 0\n",
    "# print(test_results)\n",
    "for result in test_results.keys():\n",
    "    true_val = test_results[result][1]\n",
    "    range_result = get_predicted_range(learned_topics, test_results[result][0], range_dict)\n",
    "    if range_result[0] is not None and range_result[1] is not None:\n",
    "        if int(true_val) >= range_result[0] and int(true_val) <= range_result[1]:\n",
    "            print(\"win: \" + str(range_result))\n",
    "            win += 1\n",
    "        else:\n",
    "            print(\"loss:\" + str(range_result))\n",
    "            loss += 1\n",
    "    else:\n",
    "        none_loss += 1\n",
    "print(win)\n",
    "print(loss)\n",
    "print(none_loss)\n",
    "print(\"Final results = \" + str(win/(loss + win + none_loss)))\n",
    "        \n",
    "# Then get topics for test\n",
    "# If you get similar topics for test set, choose that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
